{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_hxzrVpanrY"
      },
      "source": [
        "# Deep Learning for Malaria Diagnosis\n",
        "This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018) and (Jason Brownlee, 2019). Acknowledge to NIH and Bangalor Hospital who make available this malaria dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DyHvXlda9rH"
      },
      "source": [
        "Malaria is an infectuous disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes.\n",
        "\n",
        "The Malaria burden with some key figures:\n",
        "<font color='red'>\n",
        "* More than 219 million cases\n",
        "* Over 430 000 deaths in 2017 (Mostly: children & pregnants)\n",
        "* 80% in 15 countries of Africa & India\n",
        "  </font>\n",
        "\n",
        "![MalariaBurd](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaBurden.png?raw=1)\n",
        "\n",
        "The malaria diagnosis is performed using blood test:\n",
        "* Collect patient blood smear\n",
        "* Microscopic visualisation of the parasit\n",
        "\n",
        "![MalariaDiag](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaDiag.png?raw=1)\n",
        "  \n",
        "Main issues related to traditional diagnosis:\n",
        "<font color='#ed7d31'>\n",
        "* resource-constrained regions\n",
        "* time needed and delays\n",
        "* diagnosis accuracy and cost\n",
        "</font>\n",
        "\n",
        "The objective of this notebook is to apply modern deep learning techniques to perform medical image analysis for malaria diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5qBTeqkrJ88"
      },
      "source": [
        "*This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018), (Adrian Rosebrock, 2018) and (Jason Brownlee, 2019)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5rb4bmdMRf"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxaLbRUnYWTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec31d8d2-f948-4b4d-bb59-01230633ebff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Parasitized  Uninfected\n"
          ]
        }
      ],
      "source": [
        "#Mount the local drive project_forder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/cell_images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIfORUX7ccHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "af7cdf26-bded-4696-bc26-03de9c23e0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Use GPU: Please check if the outpout is '/device:GPU:0'\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "#from tensorflow.python.client import device_lib\n",
        "#device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1o6Cd7dV6Z"
      },
      "source": [
        "## Populating namespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Ph8e1uojEC"
      },
      "outputs": [],
      "source": [
        "# Importing basic libraries\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D as Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOvmLtdRgSIb"
      },
      "outputs": [],
      "source": [
        "# Define the useful paths for data accessibility\n",
        "ai_project = '.' #\"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "cell_images_dir = os.path.join(ai_project,'cell_images')\n",
        "training_path = os.path.join(ai_project,'train')\n",
        "testing_path = os.path.join(ai_project,'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DKlCJcj31w"
      },
      "source": [
        "## Prepare DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "midATIuUq7H7"
      },
      "source": [
        "### *Download* DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCT2ogQdeHPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fab4b7-ba1b-4fcf-ecc2-32622989a911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-06 05:21:18--  https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
            "Resolving data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)... 3.163.189.81, 3.163.189.83, 3.163.189.96, ...\n",
            "Connecting to data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)|3.163.189.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353452851 (337M) [application/zip]\n",
            "Saving to: â€˜cell_images.zipâ€™\n",
            "\n",
            "cell_images.zip     100%[===================>] 337.08M  25.6MB/s    in 4.2s    \n",
            "\n",
            "2025-10-06 05:21:22 (80.7 MB/s) - â€˜cell_images.zipâ€™ saved [353452851/353452851]\n",
            "\n",
            "cell_images  cell_images.zip  drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
        "downloadData = True\n",
        "if downloadData == True:\n",
        "  indrive = False\n",
        "  if indrive == True:\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
        "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "  else: #incloud google server\n",
        "    !rm -rf cell_images.*\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
        "    !unzip cell_images.zip >/dev/null 2>&1\n",
        "    !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1LUJGE9U2vW"
      },
      "source": [
        "## Baseline CNN Model\n",
        "Define a basic ConvNet defined with ConvLayer: Conv2D => MaxPooling2D followed by Flatten => Dense => Dense(output)\n",
        "\n",
        "![ConvNet](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/ConvNet.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ADVANCED CNN MODEL FOR MALARIA CLASSIFICATION - OPTIMIZED VERSION\n",
        "# 10 Epochs for Faster Training\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
        "                                      Dropout, BatchNormalization,\n",
        "                                      GlobalAveragePooling2D)\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
        "                                        ModelCheckpoint, Callback)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             roc_curve, auc, precision_recall_curve,\n",
        "                             accuracy_score, precision_score,\n",
        "                             recall_score, f1_score)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Enable mixed precision for faster training\n",
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)"
      ],
      "metadata": {
        "id": "gexBx0okq-5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DETAILED CHECK: What's inside cell_images folder?\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"DETAILED CHECK: Exploring 'cell_images' folder\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "cell_images_path = 'cell_images'\n",
        "\n",
        "if os.path.exists(cell_images_path):\n",
        "    print(f\"\\n Contents of '{cell_images_path}/':\")\n",
        "\n",
        "    for item in os.listdir(cell_images_path):\n",
        "        item_path = os.path.join(cell_images_path, item)\n",
        "\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"\\n    {item}/\")\n",
        "\n",
        "            # Check what's inside this subfolder\n",
        "            sub_items = os.listdir(item_path)\n",
        "            print(f\"      Contains {len(sub_items)} items\")\n",
        "\n",
        "            # Show first few items\n",
        "            for sub_item in sub_items[:5]:\n",
        "                sub_path = os.path.join(item_path, sub_item)\n",
        "                if os.path.isdir(sub_path):\n",
        "                    num_files = len(os.listdir(sub_path))\n",
        "                    print(f\"       {sub_item}/ ({num_files} files)\")\n",
        "                else:\n",
        "                    print(f\"       {sub_item}\")\n",
        "\n",
        "            if len(sub_items) > 5:\n",
        "                print(f\"      ... and {len(sub_items) - 5} more items\")\n",
        "        else:\n",
        "            print(f\"    {item}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zVSq27t5Qn0",
        "outputId": "cca1ed81-f843-494a-f5c6-5a8d1073cf7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DETAILED CHECK: Exploring 'cell_images' folder\n",
            "======================================================================\n",
            "\n",
            "ðŸ“ Contents of 'cell_images/':\n",
            "\n",
            "   ðŸ“ Parasitized/\n",
            "      Contains 13780 items\n",
            "      ðŸ“„ C39P4thinF_original_IMG_20150622_105335_cell_8.png\n",
            "      ðŸ“„ C143P104ThinF_IMG_20151005_230100_cell_158.png\n",
            "      ðŸ“„ C60P21thinF_IMG_20150803_144629_cell_6.png\n",
            "      ðŸ“„ C132P93ThinF_IMG_20151004_152505_cell_113.png\n",
            "      ðŸ“„ C126P87ThinF_IMG_20151004_105342_cell_114.png\n",
            "      ... and 13775 more items\n",
            "\n",
            "   ðŸ“ Uninfected/\n",
            "      Contains 13780 items\n",
            "      ðŸ“„ C143P104ThinF_IMG_20151005_230100_cell_134.png\n",
            "      ðŸ“„ C92P53ThinF_IMG_20150821_151722_cell_33.png\n",
            "      ðŸ“„ C146P107ThinF_IMG_20151018_140342_cell_147.png\n",
            "      ðŸ“„ C62P23N_ThinF_IMG_20150818_133527_cell_74.png\n",
            "      ðŸ“„ C74P35_ThinF_IMG_20150815_114401_cell_15.png\n",
            "      ... and 13775 more items\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SPLIT DATA INTO TRAIN AND TEST SETS\n",
        "# =============================================================================\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(source_dir, train_dir, test_dir, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into train and test sets\n",
        "    \"\"\"\n",
        "    # Create directories\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Get class folders\n",
        "    classes = [d for d in os.listdir(source_dir)\n",
        "               if os.path.isdir(os.path.join(source_dir, d))]\n",
        "\n",
        "    print(f\"Found classes: {classes}\")\n",
        "\n",
        "    for class_name in classes:\n",
        "        print(f\"\\nProcessing class: {class_name}\")\n",
        "\n",
        "        # Create class directories in train and test\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        test_class_dir = os.path.join(test_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "        # Get all images for this class\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        images = [f for f in os.listdir(class_dir)\n",
        "                 if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        print(f\"  Total images: {len(images)}\")\n",
        "\n",
        "        # Split into train and test\n",
        "        train_images, test_images = train_test_split(\n",
        "            images, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"  Train: {len(train_images)}, Test: {len(test_images)}\")\n",
        "\n",
        "        # Copy files to train directory\n",
        "        for img in train_images:\n",
        "            src = os.path.join(class_dir, img)\n",
        "            dst = os.path.join(train_class_dir, img)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "        # Copy files to test directory\n",
        "        for img in test_images:\n",
        "            src = os.path.join(class_dir, img)\n",
        "            dst = os.path.join(test_class_dir, img)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "    print(\"\\nâœ“ Data split completed successfully!\")\n",
        "\n",
        "# Check if train/test already exist\n",
        "if not os.path.exists('train') or not os.path.exists('test'):\n",
        "    print(\"=\" * 70)\n",
        "    print(\"SPLITTING DATA INTO TRAIN AND TEST SETS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "    split_data(\n",
        "        source_dir='cell_images',\n",
        "        train_dir='train',\n",
        "        test_dir='test',\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"VERIFICATION\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for split in ['train', 'test']:\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        for class_name in os.listdir(split):\n",
        "            class_path = os.path.join(split, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                num_images = len(os.listdir(class_path))\n",
        "                print(f\"  {class_name}: {num_images} images\")\n",
        "else:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"âœ“ Train and Test directories already exist\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for split in ['train', 'test']:\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        for class_name in os.listdir(split):\n",
        "            class_path = os.path.join(split, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                num_images = len(os.listdir(class_path))\n",
        "                print(f\"  {class_name}: {num_images} images\")"
      ],
      "metadata": {
        "id": "HSovHHzqrF3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab011af-d45d-488f-d4b3-17031b5dad33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SPLITTING DATA INTO TRAIN AND TEST SETS\n",
            "======================================================================\n",
            "This may take a few minutes...\n",
            "\n",
            "Found classes: ['Parasitized', 'Uninfected']\n",
            "\n",
            "Processing class: Parasitized\n",
            "  Total images: 13779\n",
            "  Train: 11023, Test: 2756\n",
            "\n",
            "Processing class: Uninfected\n",
            "  Total images: 13779\n",
            "  Train: 11023, Test: 2756\n",
            "\n",
            "âœ“ Data split completed successfully!\n",
            "\n",
            "======================================================================\n",
            "VERIFICATION\n",
            "======================================================================\n",
            "\n",
            "TRAIN:\n",
            "  Parasitized: 11023 images\n",
            "  Uninfected: 11023 images\n",
            "\n",
            "TEST:\n",
            "  Parasitized: 2756 images\n",
            "  Uninfected: 2756 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION - OPTIMIZED FOR SPEED\n",
        "# =============================================================================\n",
        "class Config:\n",
        "    IMG_SIZE = (124, 124)\n",
        "    BATCH_SIZE = 64  # Increased for faster training\n",
        "    EPOCHS = 10  # REDUCED FROM 30 TO 10\n",
        "    INPUT_SHAPE = (124, 124, 3)\n",
        "    TRAIN_DIR = 'train'\n",
        "    TEST_DIR = 'test'\n",
        "    RESULTS_DIR = 'advanced_cnn_results'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create results directory\n",
        "os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\nâš¡ OPTIMIZED CONFIGURATION:\")\n",
        "print(f\"   Epochs: {config.EPOCHS}\")\n",
        "print(f\"   Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"   Mixed Precision: Enabled\")\n",
        "print(f\"   Expected training time: ~5-10 minutes per experiment\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP3h8ctL6-tC",
        "outputId": "0b95f484-f8e6-40c2-cd44-de8060ab11c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âš¡ OPTIMIZED CONFIGURATION:\n",
            "   Epochs: 10\n",
            "   Batch Size: 64\n",
            "   Mixed Precision: Enabled\n",
            "   Expected training time: ~5-10 minutes per experiment\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUATION FUNCTIONS\n",
        "# =============================================================================\n",
        "def plot_learning_curves(history, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot training and validation loss and accuracy\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    axes[0].set_title(f'{experiment_name}\\nTraining and Validation Loss',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].legend(fontsize=10)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot accuracy\n",
        "    axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "    axes[1].set_title(f'{experiment_name}\\nTraining and Validation Accuracy',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[1].legend(fontsize=10)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{config.RESULTS_DIR}/{experiment_name}_learning_curves.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Parasitized', 'Uninfected'],\n",
        "                yticklabels=['Parasitized', 'Uninfected'],\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.title(f'{experiment_name}\\nConfusion Matrix',\n",
        "             fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{config.RESULTS_DIR}/{experiment_name}_confusion_matrix.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred_proba, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot ROC curve\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "            label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "            label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title(f'{experiment_name}\\nROC Curve', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{config.RESULTS_DIR}/{experiment_name}_roc_curve.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "def evaluate_model(model, test_generator, experiment_name):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation\n",
        "    \"\"\"\n",
        "    # Reset generator\n",
        "    test_generator.reset()\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_proba = model.predict(test_generator, verbose=0)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    # Plot visualizations\n",
        "    plot_confusion_matrix(y_true, y_pred, experiment_name)\n",
        "    roc_auc = plot_roc_curve(y_true, y_pred_proba, experiment_name)\n",
        "\n",
        "    # Return metrics dictionary\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'AUC': roc_auc\n",
        "    }\n",
        "\n",
        "    return metrics, y_true, y_pred"
      ],
      "metadata": {
        "id": "ofW7VoHf-Hcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DATA PREPARATION\n",
        "# =============================================================================\n",
        "def prepare_data_generators(augmentation_level='moderate'):\n",
        "    \"\"\"\n",
        "    Prepare data generators with different augmentation levels\n",
        "    \"\"\"\n",
        "    # Training data generators with different augmentation levels\n",
        "    if augmentation_level == 'none':\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    elif augmentation_level == 'light':\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=10,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "    elif augmentation_level == 'moderate':\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "    else:  # aggressive\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=40,\n",
        "            width_shift_range=0.3,\n",
        "            height_shift_range=0.3,\n",
        "            shear_range=0.3,\n",
        "            zoom_range=0.3,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            brightness_range=[0.7, 1.3],\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "    # Validation data (no augmentation)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Load data\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        config.TRAIN_DIR,\n",
        "        target_size=config.IMG_SIZE,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        config.TEST_DIR,\n",
        "        target_size=config.IMG_SIZE,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, test_generator"
      ],
      "metadata": {
        "id": "K9urQSZsrJp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODEL ARCHITECTURES\n",
        "# =============================================================================\n",
        "def create_advanced_cnn_v1(dropout_rate=0.5, l2_reg=0.001):\n",
        "    \"\"\"\n",
        "    Experiment 1-3: Base advanced architecture with varying regularization\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # Block 1\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=l2(l2_reg), input_shape=config.INPUT_SHAPE),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(dropout_rate * 0.5),\n",
        "\n",
        "        # Block 2\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=l2(l2_reg)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(dropout_rate * 0.5),\n",
        "\n",
        "        # Block 3\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=l2(l2_reg)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(dropout_rate * 0.5),\n",
        "\n",
        "        # Block 4\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "\n",
        "        # Dense layers\n",
        "        Dense(512, activation='relu', kernel_regularizer=l2(l2_reg)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(dropout_rate * 0.6),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')  # Float32 for stability\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_deep_cnn(num_blocks=5):\n",
        "    \"\"\"\n",
        "    Experiment 4-5: Deeper architecture\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    filters = [32, 64, 128, 256, 512]\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        if i == 0:\n",
        "            model.add(Conv2D(filters[i], (3, 3), activation='relu',\n",
        "                           padding='same', input_shape=config.INPUT_SHAPE))\n",
        "        else:\n",
        "            model.add(Conv2D(filters[i], (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(filters[i], (3, 3), activation='relu', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        if i < num_blocks - 1:\n",
        "            model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid', dtype='float32'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_wide_cnn():\n",
        "    \"\"\"\n",
        "    Experiment 6: Wider architecture (more filters per layer)\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               input_shape=config.INPUT_SHAPE),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "bv8B_SsxrNi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXPERIMENT RUNNER\n",
        "# =============================================================================\n",
        "def run_experiment(experiment_config):\n",
        "    \"\"\"\n",
        "    Run a single experiment with given configuration\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Running: {experiment_config['name']}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # Prepare data\n",
        "    train_gen, test_gen = prepare_data_generators(\n",
        "        experiment_config.get('augmentation', 'moderate')\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = experiment_config['model_fn'](**experiment_config.get('model_params', {}))\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = experiment_config.get('optimizer', Adam(learning_rate=0.0001))\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(),\n",
        "                tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    # Callbacks - adjusted for 10 epochs\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n",
        "    ]\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=config.EPOCHS,\n",
        "        validation_data=test_gen,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Plot learning curves\n",
        "    plot_learning_curves(history, experiment_config['name'])\n",
        "\n",
        "    # Evaluate model\n",
        "    metrics, y_true, y_pred = evaluate_model(model, test_gen, experiment_config['name'])\n",
        "\n",
        "    # Add training time and parameters\n",
        "    elapsed_time = (datetime.now() - start_time).total_seconds()\n",
        "    metrics['Parameters'] = model.count_params()\n",
        "    metrics['Final_Train_Acc'] = history.history['accuracy'][-1]\n",
        "    metrics['Final_Val_Acc'] = history.history['val_accuracy'][-1]\n",
        "    metrics['Training_Time_Sec'] = elapsed_time\n",
        "\n",
        "    return metrics, model, history"
      ],
      "metadata": {
        "id": "zNw9926XraSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DEFINE ALL 7 EXPERIMENTS\n",
        "# =============================================================================\n",
        "experiments = [\n",
        "    {\n",
        "        'name': 'Exp1_Baseline_Moderate_Aug',\n",
        "        'description': 'Baseline advanced CNN with moderate augmentation',\n",
        "        'model_fn': create_advanced_cnn_v1,\n",
        "        'model_params': {'dropout_rate': 0.5, 'l2_reg': 0.001},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': Adam(learning_rate=0.0001)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp2_High_Dropout',\n",
        "        'description': 'Increased dropout for better regularization',\n",
        "        'model_fn': create_advanced_cnn_v1,\n",
        "        'model_params': {'dropout_rate': 0.7, 'l2_reg': 0.001},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': Adam(learning_rate=0.0001)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp3_Strong_L2_Reg',\n",
        "        'description': 'Stronger L2 regularization',\n",
        "        'model_fn': create_advanced_cnn_v1,\n",
        "        'model_params': {'dropout_rate': 0.5, 'l2_reg': 0.01},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': Adam(learning_rate=0.0001)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp4_Deeper_Network',\n",
        "        'description': 'Deeper architecture with 5 convolutional blocks',\n",
        "        'model_fn': create_deep_cnn,\n",
        "        'model_params': {'num_blocks': 5},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': Adam(learning_rate=0.00005)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp5_Aggressive_Augmentation',\n",
        "        'description': 'Aggressive data augmentation',\n",
        "        'model_fn': create_advanced_cnn_v1,\n",
        "        'model_params': {'dropout_rate': 0.5, 'l2_reg': 0.001},\n",
        "        'augmentation': 'aggressive',\n",
        "        'optimizer': Adam(learning_rate=0.0001)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp6_Wide_Network',\n",
        "        'description': 'Wider network with more filters',\n",
        "        'model_fn': create_wide_cnn,\n",
        "        'model_params': {},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': Adam(learning_rate=0.00005)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Exp7_SGD_Optimizer',\n",
        "        'description': 'Using SGD with momentum instead of Adam',\n",
        "        'model_fn': create_advanced_cnn_v1,\n",
        "        'model_params': {'dropout_rate': 0.5, 'l2_reg': 0.001},\n",
        "        'augmentation': 'moderate',\n",
        "        'optimizer': SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "0fhDqTCMrdxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RUN ALL EXPERIMENTS\n",
        "# =============================================================================\n",
        "all_results = []\n",
        "total_start_time = datetime.now()\n",
        "\n",
        "for i, exp in enumerate(experiments, 1):\n",
        "    try:\n",
        "        print(f\"\\nâš¡ Progress: {i}/{len(experiments)} experiments\")\n",
        "        metrics, model, history = run_experiment(exp)\n",
        "\n",
        "        result = {\n",
        "            'Experiment': exp['name'],\n",
        "            'Description': exp['description'],\n",
        "            **metrics\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "        # Save model\n",
        "        model.save(f\"{config.RESULTS_DIR}/{exp['name']}_model.keras\")\n",
        "\n",
        "        print(f\"\\nâœ“ {exp['name']} completed successfully!\")\n",
        "        print(f\"  Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "        print(f\"  F1-Score: {metrics['F1-Score']:.4f}\")\n",
        "        print(f\"  AUC: {metrics['AUC']:.4f}\")\n",
        "        print(f\"  Training Time: {metrics['Training_Time_Sec']:.1f} seconds\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâœ— Error in {exp['name']}: {str(e)}\\n\")\n",
        "        continue\n",
        "\n",
        "total_elapsed = (datetime.now() - total_start_time).total_seconds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRm5BAV0rgd_",
        "outputId": "9e854650-25e2-433e-c4cd-334740e82464"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âš¡ Progress: 1/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp1_Baseline_Moderate_Aug\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 391ms/step - accuracy: 0.6941 - loss: 1.1214 - precision: 0.6844 - recall: 0.7212 - val_accuracy: 0.5000 - val_loss: 2.0659 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.8756 - loss: 0.7959 - precision: 0.8464 - recall: 0.9201 - val_accuracy: 0.6573 - val_loss: 1.4984 - val_precision: 0.5934 - val_recall: 0.9996 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 314ms/step - accuracy: 0.9038 - loss: 0.7159 - precision: 0.8770 - recall: 0.9399 - val_accuracy: 0.8911 - val_loss: 0.7138 - val_precision: 0.8241 - val_recall: 0.9946 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 313ms/step - accuracy: 0.9168 - loss: 0.6691 - precision: 0.8899 - recall: 0.9515 - val_accuracy: 0.9340 - val_loss: 0.6057 - val_precision: 0.8929 - val_recall: 0.9862 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.9225 - loss: 0.6363 - precision: 0.8979 - recall: 0.9553 - val_accuracy: 0.9048 - val_loss: 0.6496 - val_precision: 0.8431 - val_recall: 0.9946 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 312ms/step - accuracy: 0.9229 - loss: 0.6184 - precision: 0.8994 - recall: 0.9563 - val_accuracy: 0.9274 - val_loss: 0.5917 - val_precision: 0.8793 - val_recall: 0.9909 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 317ms/step - accuracy: 0.9261 - loss: 0.5861 - precision: 0.9052 - recall: 0.9532 - val_accuracy: 0.9434 - val_loss: 0.5557 - val_precision: 0.9071 - val_recall: 0.9880 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.9327 - loss: 0.5487 - precision: 0.9108 - recall: 0.9593 - val_accuracy: 0.9552 - val_loss: 0.4780 - val_precision: 0.9336 - val_recall: 0.9800 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 312ms/step - accuracy: 0.9274 - loss: 0.5391 - precision: 0.9046 - recall: 0.9543 - val_accuracy: 0.9494 - val_loss: 0.4712 - val_precision: 0.9180 - val_recall: 0.9869 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.9330 - loss: 0.5074 - precision: 0.9073 - recall: 0.9625 - val_accuracy: 0.9512 - val_loss: 0.4560 - val_precision: 0.9217 - val_recall: 0.9862 - learning_rate: 1.0000e-04\n",
            "\n",
            "âœ“ Exp1_Baseline_Moderate_Aug completed successfully!\n",
            "  Accuracy: 0.9512\n",
            "  F1-Score: 0.9528\n",
            "  AUC: 0.9884\n",
            "  Training Time: 1161.5 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 2/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp2_High_Dropout\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 349ms/step - accuracy: 0.6058 - loss: 1.3971 - precision_1: 0.6194 - recall_1: 0.5446 - val_accuracy: 0.5000 - val_loss: 2.8253 - val_precision_1: 0.5000 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.8217 - loss: 0.9293 - precision_1: 0.7925 - recall_1: 0.8715 - val_accuracy: 0.7286 - val_loss: 1.3645 - val_precision_1: 0.6499 - val_recall_1: 0.9909 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 327ms/step - accuracy: 0.8677 - loss: 0.8186 - precision_1: 0.8358 - recall_1: 0.9181 - val_accuracy: 0.8028 - val_loss: 1.0514 - val_precision_1: 0.7185 - val_recall_1: 0.9956 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.8870 - loss: 0.7683 - precision_1: 0.8562 - recall_1: 0.9355 - val_accuracy: 0.8443 - val_loss: 0.8698 - val_precision_1: 0.7639 - val_recall_1: 0.9967 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.9054 - loss: 0.7107 - precision_1: 0.8760 - recall_1: 0.9468 - val_accuracy: 0.8959 - val_loss: 0.7113 - val_precision_1: 0.8312 - val_recall_1: 0.9935 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 318ms/step - accuracy: 0.9133 - loss: 0.6736 - precision_1: 0.8837 - recall_1: 0.9531 - val_accuracy: 0.9118 - val_loss: 0.6514 - val_precision_1: 0.8545 - val_recall_1: 0.9927 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 317ms/step - accuracy: 0.9210 - loss: 0.6448 - precision_1: 0.8944 - recall_1: 0.9566 - val_accuracy: 0.9098 - val_loss: 0.6564 - val_precision_1: 0.8511 - val_recall_1: 0.9935 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 313ms/step - accuracy: 0.9215 - loss: 0.6250 - precision_1: 0.8937 - recall_1: 0.9562 - val_accuracy: 0.9341 - val_loss: 0.5727 - val_precision_1: 0.8919 - val_recall_1: 0.9880 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 317ms/step - accuracy: 0.9286 - loss: 0.5945 - precision_1: 0.9043 - recall_1: 0.9595 - val_accuracy: 0.9198 - val_loss: 0.5960 - val_precision_1: 0.8671 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.9212 - loss: 0.5854 - precision_1: 0.8940 - recall_1: 0.9562 - val_accuracy: 0.9147 - val_loss: 0.5689 - val_precision_1: 0.8594 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
            "\n",
            "âœ“ Exp2_High_Dropout completed successfully!\n",
            "  Accuracy: 0.9147\n",
            "  F1-Score: 0.9208\n",
            "  AUC: 0.9888\n",
            "  Training Time: 1130.0 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 3/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp3_Strong_L2_Reg\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 352ms/step - accuracy: 0.6737 - loss: 5.1949 - precision_2: 0.6682 - recall_2: 0.6444 - val_accuracy: 0.5000 - val_loss: 6.3101 - val_precision_2: 0.5000 - val_recall_2: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.8754 - loss: 3.8856 - precision_2: 0.8424 - recall_2: 0.9240 - val_accuracy: 0.6067 - val_loss: 4.0582 - val_precision_2: 0.5597 - val_recall_2: 0.9996 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.9076 - loss: 2.9754 - precision_2: 0.8795 - recall_2: 0.9454 - val_accuracy: 0.8353 - val_loss: 2.6821 - val_precision_2: 0.7537 - val_recall_2: 0.9960 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 330ms/step - accuracy: 0.9129 - loss: 2.2916 - precision_2: 0.8831 - recall_2: 0.9502 - val_accuracy: 0.8452 - val_loss: 2.0526 - val_precision_2: 0.7653 - val_recall_2: 0.9960 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 312ms/step - accuracy: 0.9247 - loss: 1.7544 - precision_2: 0.9013 - recall_2: 0.9549 - val_accuracy: 0.8585 - val_loss: 1.5947 - val_precision_2: 0.7810 - val_recall_2: 0.9964 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 327ms/step - accuracy: 0.9239 - loss: 1.3709 - precision_2: 0.8997 - recall_2: 0.9542 - val_accuracy: 0.8942 - val_loss: 1.2016 - val_precision_2: 0.8278 - val_recall_2: 0.9956 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 314ms/step - accuracy: 0.9280 - loss: 1.0636 - precision_2: 0.9029 - recall_2: 0.9576 - val_accuracy: 0.9369 - val_loss: 0.8767 - val_precision_2: 0.8942 - val_recall_2: 0.9909 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 312ms/step - accuracy: 0.9313 - loss: 0.8455 - precision_2: 0.9098 - recall_2: 0.9579 - val_accuracy: 0.9478 - val_loss: 0.6853 - val_precision_2: 0.9152 - val_recall_2: 0.9869 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 317ms/step - accuracy: 0.9343 - loss: 0.6749 - precision_2: 0.9148 - recall_2: 0.9585 - val_accuracy: 0.9272 - val_loss: 0.6156 - val_precision_2: 0.8770 - val_recall_2: 0.9938 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 326ms/step - accuracy: 0.9338 - loss: 0.5574 - precision_2: 0.9107 - recall_2: 0.9610 - val_accuracy: 0.9448 - val_loss: 0.4611 - val_precision_2: 0.9070 - val_recall_2: 0.9913 - learning_rate: 1.0000e-04\n",
            "\n",
            "âœ“ Exp3_Strong_L2_Reg completed successfully!\n",
            "  Accuracy: 0.9448\n",
            "  F1-Score: 0.9473\n",
            "  AUC: 0.9895\n",
            "  Training Time: 1138.0 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 4/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp4_Deeper_Network\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 385ms/step - accuracy: 0.6102 - loss: 0.7803 - precision_3: 0.6120 - recall_3: 0.6101 - val_accuracy: 0.5000 - val_loss: 1.7314 - val_precision_3: 0.5000 - val_recall_3: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 319ms/step - accuracy: 0.7376 - loss: 0.5704 - precision_3: 0.7307 - recall_3: 0.7439 - val_accuracy: 0.6667 - val_loss: 0.8054 - val_precision_3: 0.6004 - val_recall_3: 0.9967 - learning_rate: 5.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 318ms/step - accuracy: 0.8404 - loss: 0.3794 - precision_3: 0.8197 - recall_3: 0.8714 - val_accuracy: 0.7391 - val_loss: 0.8158 - val_precision_3: 0.6584 - val_recall_3: 0.9938 - learning_rate: 5.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 324ms/step - accuracy: 0.8708 - loss: 0.3265 - precision_3: 0.8429 - recall_3: 0.9147 - val_accuracy: 0.8269 - val_loss: 0.4407 - val_precision_3: 0.7452 - val_recall_3: 0.9935 - learning_rate: 5.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 320ms/step - accuracy: 0.8903 - loss: 0.2929 - precision_3: 0.8670 - recall_3: 0.9247 - val_accuracy: 0.8342 - val_loss: 0.4501 - val_precision_3: 0.7530 - val_recall_3: 0.9946 - learning_rate: 5.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 325ms/step - accuracy: 0.9035 - loss: 0.2627 - precision_3: 0.8760 - recall_3: 0.9403 - val_accuracy: 0.8543 - val_loss: 0.4071 - val_precision_3: 0.7770 - val_recall_3: 0.9938 - learning_rate: 5.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 319ms/step - accuracy: 0.9071 - loss: 0.2497 - precision_3: 0.8794 - recall_3: 0.9416 - val_accuracy: 0.8781 - val_loss: 0.3606 - val_precision_3: 0.8074 - val_recall_3: 0.9931 - learning_rate: 5.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 320ms/step - accuracy: 0.9156 - loss: 0.2361 - precision_3: 0.8937 - recall_3: 0.9450 - val_accuracy: 0.8674 - val_loss: 0.3174 - val_precision_3: 0.7934 - val_recall_3: 0.9935 - learning_rate: 5.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 329ms/step - accuracy: 0.9206 - loss: 0.2261 - precision_3: 0.8962 - recall_3: 0.9488 - val_accuracy: 0.9243 - val_loss: 0.2228 - val_precision_3: 0.8762 - val_recall_3: 0.9884 - learning_rate: 5.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 321ms/step - accuracy: 0.9202 - loss: 0.2233 - precision_3: 0.8968 - recall_3: 0.9507 - val_accuracy: 0.9204 - val_loss: 0.2324 - val_precision_3: 0.8705 - val_recall_3: 0.9877 - learning_rate: 5.0000e-05\n",
            "\n",
            "âœ“ Exp4_Deeper_Network completed successfully!\n",
            "  Accuracy: 0.9243\n",
            "  F1-Score: 0.9289\n",
            "  AUC: 0.9865\n",
            "  Training Time: 1170.1 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 5/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp5_Aggressive_Augmentation\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 403ms/step - accuracy: 0.6181 - loss: 1.2292 - precision_4: 0.6145 - recall_4: 0.6364 - val_accuracy: 0.5000 - val_loss: 2.4696 - val_precision_4: 0.5000 - val_recall_4: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 352ms/step - accuracy: 0.8241 - loss: 0.8897 - precision_4: 0.7827 - recall_4: 0.8945 - val_accuracy: 0.6972 - val_loss: 1.2157 - val_precision_4: 0.6229 - val_recall_4: 0.9996 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 357ms/step - accuracy: 0.8587 - loss: 0.8095 - precision_4: 0.8160 - recall_4: 0.9256 - val_accuracy: 0.8864 - val_loss: 0.7454 - val_precision_4: 0.8173 - val_recall_4: 0.9953 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 354ms/step - accuracy: 0.8771 - loss: 0.7547 - precision_4: 0.8370 - recall_4: 0.9376 - val_accuracy: 0.9258 - val_loss: 0.6211 - val_precision_4: 0.8779 - val_recall_4: 0.9891 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 352ms/step - accuracy: 0.8841 - loss: 0.7248 - precision_4: 0.8433 - recall_4: 0.9418 - val_accuracy: 0.9497 - val_loss: 0.5525 - val_precision_4: 0.9215 - val_recall_4: 0.9833 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 355ms/step - accuracy: 0.8883 - loss: 0.6951 - precision_4: 0.8472 - recall_4: 0.9470 - val_accuracy: 0.9369 - val_loss: 0.5559 - val_precision_4: 0.8963 - val_recall_4: 0.9880 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 352ms/step - accuracy: 0.8958 - loss: 0.6587 - precision_4: 0.8584 - recall_4: 0.9498 - val_accuracy: 0.9501 - val_loss: 0.5148 - val_precision_4: 0.9229 - val_recall_4: 0.9822 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 356ms/step - accuracy: 0.8989 - loss: 0.6299 - precision_4: 0.8617 - recall_4: 0.9489 - val_accuracy: 0.9496 - val_loss: 0.4955 - val_precision_4: 0.9229 - val_recall_4: 0.9811 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 352ms/step - accuracy: 0.9010 - loss: 0.6068 - precision_4: 0.8649 - recall_4: 0.9518 - val_accuracy: 0.9450 - val_loss: 0.4769 - val_precision_4: 0.9117 - val_recall_4: 0.9855 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 352ms/step - accuracy: 0.9074 - loss: 0.5750 - precision_4: 0.8739 - recall_4: 0.9534 - val_accuracy: 0.9525 - val_loss: 0.4490 - val_precision_4: 0.9291 - val_recall_4: 0.9797 - learning_rate: 1.0000e-04\n",
            "\n",
            "âœ“ Exp5_Aggressive_Augmentation completed successfully!\n",
            "  Accuracy: 0.9525\n",
            "  F1-Score: 0.9537\n",
            "  AUC: 0.9869\n",
            "  Training Time: 1283.3 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 6/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp6_Wide_Network\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 426ms/step - accuracy: 0.6253 - loss: 0.7398 - precision_5: 0.6233 - recall_5: 0.6184 - val_accuracy: 0.5000 - val_loss: 2.6595 - val_precision_5: 0.5000 - val_recall_5: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 330ms/step - accuracy: 0.8455 - loss: 0.3842 - precision_5: 0.8187 - recall_5: 0.8867 - val_accuracy: 0.6624 - val_loss: 1.1406 - val_precision_5: 0.5983 - val_recall_5: 0.9884 - learning_rate: 5.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 332ms/step - accuracy: 0.8878 - loss: 0.3060 - precision_5: 0.8555 - recall_5: 0.9325 - val_accuracy: 0.8476 - val_loss: 0.5133 - val_precision_5: 0.7677 - val_recall_5: 0.9967 - learning_rate: 5.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 328ms/step - accuracy: 0.8985 - loss: 0.2793 - precision_5: 0.8682 - recall_5: 0.9392 - val_accuracy: 0.8186 - val_loss: 0.5353 - val_precision_5: 0.7345 - val_recall_5: 0.9978 - learning_rate: 5.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 335ms/step - accuracy: 0.9146 - loss: 0.2443 - precision_5: 0.8872 - recall_5: 0.9496 - val_accuracy: 0.9037 - val_loss: 0.3243 - val_precision_5: 0.8426 - val_recall_5: 0.9927 - learning_rate: 5.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 330ms/step - accuracy: 0.9206 - loss: 0.2258 - precision_5: 0.8960 - recall_5: 0.9524 - val_accuracy: 0.9064 - val_loss: 0.2526 - val_precision_5: 0.8459 - val_recall_5: 0.9938 - learning_rate: 5.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 334ms/step - accuracy: 0.9234 - loss: 0.2224 - precision_5: 0.8974 - recall_5: 0.9563 - val_accuracy: 0.9387 - val_loss: 0.1810 - val_precision_5: 0.8977 - val_recall_5: 0.9902 - learning_rate: 5.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 331ms/step - accuracy: 0.9253 - loss: 0.2143 - precision_5: 0.9002 - recall_5: 0.9555 - val_accuracy: 0.9138 - val_loss: 0.2454 - val_precision_5: 0.8563 - val_recall_5: 0.9946 - learning_rate: 5.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 329ms/step - accuracy: 0.9315 - loss: 0.1997 - precision_5: 0.9101 - recall_5: 0.9582 - val_accuracy: 0.9380 - val_loss: 0.1691 - val_precision_5: 0.8965 - val_recall_5: 0.9902 - learning_rate: 5.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 333ms/step - accuracy: 0.9303 - loss: 0.1936 - precision_5: 0.9099 - recall_5: 0.9552 - val_accuracy: 0.9338 - val_loss: 0.1853 - val_precision_5: 0.8898 - val_recall_5: 0.9902 - learning_rate: 5.0000e-05\n",
            "\n",
            "âœ“ Exp6_Wide_Network completed successfully!\n",
            "  Accuracy: 0.9380\n",
            "  F1-Score: 0.9410\n",
            "  AUC: 0.9879\n",
            "  Training Time: 1244.2 seconds\n",
            "\n",
            "\n",
            "âš¡ Progress: 7/7 experiments\n",
            "\n",
            "================================================================================\n",
            "Running: Exp7_SGD_Optimizer\n",
            "================================================================================\n",
            "\n",
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5512 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 350ms/step - accuracy: 0.8070 - loss: 0.9172 - precision_6: 0.7814 - recall_6: 0.8449 - val_accuracy: 0.6528 - val_loss: 1.0241 - val_precision_6: 0.5903 - val_recall_6: 0.9982 - learning_rate: 0.0100\n",
            "Epoch 2/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 324ms/step - accuracy: 0.9189 - loss: 0.6563 - precision_6: 0.8935 - recall_6: 0.9532 - val_accuracy: 0.9338 - val_loss: 0.5502 - val_precision_6: 0.8960 - val_recall_6: 0.9815 - learning_rate: 0.0100\n",
            "Epoch 3/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.9285 - loss: 0.5707 - precision_6: 0.9062 - recall_6: 0.9568 - val_accuracy: 0.9260 - val_loss: 0.5150 - val_precision_6: 0.8765 - val_recall_6: 0.9917 - learning_rate: 0.0100\n",
            "Epoch 4/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 315ms/step - accuracy: 0.9279 - loss: 0.5264 - precision_6: 0.9058 - recall_6: 0.9558 - val_accuracy: 0.9267 - val_loss: 0.4887 - val_precision_6: 0.8791 - val_recall_6: 0.9895 - learning_rate: 0.0100\n",
            "Epoch 5/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 333ms/step - accuracy: 0.9328 - loss: 0.4703 - precision_6: 0.9115 - recall_6: 0.9577 - val_accuracy: 0.9497 - val_loss: 0.4301 - val_precision_6: 0.9212 - val_recall_6: 0.9837 - learning_rate: 0.0100\n",
            "Epoch 6/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 322ms/step - accuracy: 0.9374 - loss: 0.4297 - precision_6: 0.9196 - recall_6: 0.9605 - val_accuracy: 0.9436 - val_loss: 0.3903 - val_precision_6: 0.9106 - val_recall_6: 0.9837 - learning_rate: 0.0100\n",
            "Epoch 7/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 330ms/step - accuracy: 0.9379 - loss: 0.3996 - precision_6: 0.9216 - recall_6: 0.9585 - val_accuracy: 0.9579 - val_loss: 0.3222 - val_precision_6: 0.9370 - val_recall_6: 0.9819 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 320ms/step - accuracy: 0.9342 - loss: 0.3775 - precision_6: 0.9135 - recall_6: 0.9597 - val_accuracy: 0.9574 - val_loss: 0.2933 - val_precision_6: 0.9360 - val_recall_6: 0.9819 - learning_rate: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 316ms/step - accuracy: 0.9366 - loss: 0.3528 - precision_6: 0.9163 - recall_6: 0.9608 - val_accuracy: 0.9599 - val_loss: 0.2819 - val_precision_6: 0.9465 - val_recall_6: 0.9750 - learning_rate: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m345/345\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 337ms/step - accuracy: 0.9345 - loss: 0.3323 - precision_6: 0.9156 - recall_6: 0.9584 - val_accuracy: 0.9450 - val_loss: 0.2786 - val_precision_6: 0.9087 - val_recall_6: 0.9895 - learning_rate: 0.0100\n",
            "\n",
            "âœ“ Exp7_SGD_Optimizer completed successfully!\n",
            "  Accuracy: 0.9450\n",
            "  F1-Score: 0.9474\n",
            "  AUC: 0.9901\n",
            "  Training Time: 1149.4 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERATE RESULTS SUMMARY TABLE\n",
        "# =============================================================================\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['Experiment', 'Description', 'Accuracy', 'Precision',\n",
        "                'Recall', 'F1-Score', 'AUC', 'Parameters',\n",
        "                'Final_Train_Acc', 'Final_Val_Acc', 'Training_Time_Sec']\n",
        "results_df = results_df[column_order]\n",
        "\n",
        "# Format numeric columns\n",
        "numeric_cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC',\n",
        "                'Final_Train_Acc', 'Final_Val_Acc']\n",
        "for col in numeric_cols:\n",
        "    results_df[col] = results_df[col].apply(lambda x: f\"{x:.4f}\")\n",
        "\n",
        "# Format training time\n",
        "results_df['Training_Time_Sec'] = results_df['Training_Time_Sec'].apply(\n",
        "    lambda x: f\"{x:.1f}s\"\n",
        ")\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(f'{config.RESULTS_DIR}/experiments_summary.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL EXPERIMENTS COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nâ±ï¸  Total Training Time: {total_elapsed/60:.1f} minutes\")\n",
        "print(f\"âš¡ Average Time per Experiment: {total_elapsed/len(experiments):.1f} seconds\")\n",
        "print(\"\\nResults Summary Table:\")\n",
        "print(results_df.to_string(index=False))\n",
        "print(f\"\\nAll results saved to: {config.RESULTS_DIR}/\")\n",
        "print(f\"  - Learning curves for each experiment\")\n",
        "print(f\"  - Confusion matrices\")\n",
        "print(f\"  - ROC curves\")\n",
        "print(f\"  - Summary CSV table\")\n",
        "print(f\"  - Trained models (.keras format)\")\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EUy8x8SrlPr",
        "outputId": "632efc34-0d07-4590-9442-ffa57543c618"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ALL EXPERIMENTS COMPLETED!\n",
            "================================================================================\n",
            "\n",
            "â±ï¸  Total Training Time: 138.0 minutes\n",
            "âš¡ Average Time per Experiment: 1182.6 seconds\n",
            "\n",
            "Results Summary Table:\n",
            "                  Experiment                                      Description Accuracy Precision Recall F1-Score    AUC  Parameters Final_Train_Acc Final_Val_Acc Training_Time_Sec\n",
            "  Exp1_Baseline_Moderate_Aug Baseline advanced CNN with moderate augmentation   0.9512    0.9217 0.9862   0.9528 0.9884      849313          0.9335        0.9512           1161.5s\n",
            "           Exp2_High_Dropout      Increased dropout for better regularization   0.9147    0.8594 0.9917   0.9208 0.9888      849313          0.9238        0.9147           1130.0s\n",
            "          Exp3_Strong_L2_Reg                       Stronger L2 regularization   0.9448    0.9070 0.9913   0.9473 0.9895      849313          0.9340        0.9448           1138.0s\n",
            "         Exp4_Deeper_Network  Deeper architecture with 5 convolutional blocks   0.9243    0.8762 0.9884   0.9289 0.9865     5116449          0.9199        0.9204           1170.1s\n",
            "Exp5_Aggressive_Augmentation                     Aggressive data augmentation   0.9525    0.9291 0.9797   0.9537 0.9869      849313          0.9033        0.9525           1283.3s\n",
            "           Exp6_Wide_Network                  Wider network with more filters   0.9380    0.8965 0.9902   0.9410 0.9879     3384129          0.9305        0.9338           1244.2s\n",
            "          Exp7_SGD_Optimizer          Using SGD with momentum instead of Adam   0.9450    0.9087 0.9895   0.9474 0.9901      849313          0.9365        0.9450           1149.4s\n",
            "\n",
            "All results saved to: advanced_cnn_results/\n",
            "  - Learning curves for each experiment\n",
            "  - Confusion matrices\n",
            "  - ROC curves\n",
            "  - Summary CSV table\n",
            "  - Trained models (.keras format)\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}